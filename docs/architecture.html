<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Architecture • Cowork AI</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
        href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=Outfit:wght@700;800&family=JetBrains+Mono:wght@500&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link rel="stylesheet" href="/src/style.css">
</head>

<body class="bg-zinc-950 text-zinc-200">
    <!-- @partial:topbar -->

    <div class="flex min-h-screen">
        <!-- @partial:sidebar -->

        <!-- Main Content Area -->
        <main class="flex-1  relative">
            <div class="max-w-4xl mx-auto px-6 lg:px-12 pt-20 lg:pt-32 pb-20">
                <div id="content" class="prose prose-invert prose-zinc max-w-none">
                    <h1 class="text-4xl font-extrabold tracking-tight text-white mb-8 logo-font">Makix Architecture</h1>
                    <p class="text-xl text-zinc-400 leading-relaxed mb-12">
                        A hyper-deterministic, multi-phase agentic pipeline designed for zero-drift execution, complete
                        traceability, and bounded task completion.
                    </p>

                    <!-- Beautiful Architecture Image Schema -->
                    <div
                        class="my-16 rounded-2xl overflow-hidden shadow-2xl shadow-yellow-400/10 border border-white/5 bg-zinc-900 group">
                        <div class="relative w-full aspect-video">
                            <!-- Inset shadow overlay to blend image borders into dark background -->
                            <div
                                class="absolute inset-0 bg-gradient-to-t from-zinc-950 via-transparent to-zinc-950/20 z-10 pointer-events-none">
                            </div>
                            <img src="/architecture-diagram.png" alt="Makix 7-Phase Agentic Pipeline Diagram"
                                class="w-full h-full object-cover transition-transform duration-1000 group-hover:scale-105" />
                        </div>
                        <div class="p-6 bg-zinc-950 text-center relative z-20">
                            <p class="text-sm text-zinc-400 font-mono tracking-wide uppercase">The 7-Phase Autonomous
                                Workflow</p>
                        </div>
                    </div>

                    <h2 class="text-3xl font-bold text-white mb-6">The Global Architecture: A Deep Dive</h2>
                    <p class="text-zinc-300 leading-relaxed mb-6">
                        The Makix architecture is inspired by modern compiler design and bounded-runtime execution
                        engines. Unlike standard "chatbot" models which process single input-outputs loosely, Cowork
                        uses a highly structured <strong>7-Phase Pipeline</strong> that enforces boundaries around the
                        Large Language Model's reasoning.
                    </p>
                    <p class="text-zinc-300 leading-relaxed mb-12">
                        <strong>Analogy:</strong> Think of standard LLM implementations as raw computational engines out
                        in the open (they can hallucinate, get stuck in infinite loops, or forget context). The Makix
                        architecture acts as the <em>operating system</em> or <em>flight control tower</em> around that
                        engine. It directs the inputs, checks the fuel (token budget), safely plots the course
                        (planning), governs the engine during flight (execution loop), and records the flight data
                        securely (memory and tracing) before ever returning to the user.
                    </p>

                    <h3 class="text-2xl font-bold text-white mb-8">The 7-Phase Protocol</h3>

                    <!-- Phase 1 -->
                    <section class="mb-16 pb-16 border-b border-white/5">
                        <div class="flex items-center gap-4 mb-6">
                            <div
                                class="w-12 h-12 rounded-full bg-yellow-400/10 flex items-center justify-center text-yellow-400 text-xl">
                                <i class="fas fa-terminal"></i></div>
                            <h3 class="text-2xl font-bold text-white">01 CLI Invocation & Boot</h3>
                        </div>

                        <div class="space-y-6 text-zinc-300 leading-relaxed">
                            <div>
                                <h4 class="text-white font-bold mb-2">Context & Motivation</h4>
                                <p>Standard scripts and agents usually jump straight to processing the user prompt.
                                    However, in enterprise environments where permissions, constraints, and sessions
                                    must be strictly enforced, skipping a deterministic boot sequence invites
                                    unpredictability. We needed an absolute zero-state where nothing dynamic happens
                                    until the environment is confirmed secure.</p>
                            </div>

                            <div>
                                <h4 class="text-white font-bold mb-2">Algorithm & Execution</h4>
                                <p>The boot sequence is purely programmatic (non-AI). It verifies API keys, loads
                                    configuration payloads, creates explicit local workspace directories, checks
                                    firewall constraints (Trust Tiers), and loads any previous Session IDs or arguments
                                    passed via the CLI before assembling the initial state object.</p>
                            </div>

                            <div class="bg-zinc-900 border border-white/5 p-4 rounded-xl font-mono text-sm">
                                <span class="text-zinc-500">// Example Flow:</span><br>
                                <span class="text-yellow-400">$ cowork run "build my app" --trust-tier=safe</span><br>
                                <span class="text-zinc-400">-> Parses arguments, sets Trust Tier to 'safe'</span><br>
                                <span class="text-zinc-400">-> Validates .env API keys</span><br>
                                <span class="text-zinc-400">-> Resolves filesystem paths & builds State Context</span>
                            </div>

                            <div
                                class="flex items-start gap-4 p-4 bg-emerald-500/5 border border-emerald-500/20 rounded-xl">
                                <i class="fas fa-arrow-trend-up text-emerald-500 mt-1"></i>
                                <div>
                                    <strong class="text-emerald-400 block mb-1">The Gain</strong>
                                    <p class="text-sm">Guarantees a secure execution context before parsing any
                                        potentially hostile or malformed user commands. Prevents the AI from
                                        accidentally reading or writing outside of permitted bounds.</p>
                                </div>
                            </div>
                        </div>
                    </section>

                    <!-- Phase 2 -->
                    <section class="mb-16 pb-16 border-b border-white/5">
                        <div class="flex items-center gap-4 mb-6">
                            <div
                                class="w-12 h-12 rounded-full bg-amber-500/10 flex items-center justify-center text-amber-500 text-xl">
                                <i class="fas fa-shield-halved"></i></div>
                            <h3 class="text-2xl font-bold text-white">02 Input Gatekeeper</h3>
                        </div>

                        <div class="space-y-6 text-zinc-300 leading-relaxed">
                            <div>
                                <h4 class="text-white font-bold mb-2">Context & Motivation</h4>
                                <p>Users often paste massive walls of text, logs, or codebase files directly into the
                                    prompt. When language models are flooded with excessive prompt data, they experience
                                    "attention dilution," commonly forgetting instructions provided at the beginning or
                                    end of the prompt.</p>
                            </div>

                            <div>
                                <h4 class="text-white font-bold mb-2">Algorithm & Execution</h4>
                                <p>The Input Gatekeeper calculates token density for the incoming user message using a
                                    fast tokenizer. If the input exceeds the context threshold, the gatekeeper
                                    automatically strips the heavy data from the active prompt, saves it to a structured
                                    <code>session scratchpad</code> file, and reformats the user's prompt to simply
                                    reference that file.</p>
                            </div>

                            <div class="bg-zinc-900 border border-white/5 p-4 rounded-xl font-mono text-sm">
                                <span class="text-zinc-500">// Example Scenario: User pastes 10,000 lines of
                                    logs.</span><br>
                                <span class="text-zinc-400">Gatekeeper calculates 15,000 tokens.</span><br>
                                <span class="text-zinc-400">Action: Saves logs to
                                    <code>scratchpad/logs.txt</code></span><br>
                                <span class="text-amber-500">Injects to LLM: "User uploaded 15k tokens. Reference it via
                                    scratchpad tool reading 'logs.txt'."</span>
                            </div>

                            <div class="flex items-center gap-2 text-sm text-zinc-400 border-l-2 border-amber-500 pl-4">
                                <i class="fas fa-book-open"></i>
                                <span>Reference: <a href="https://arxiv.org/abs/2307.03172" target="_blank"
                                        class="text-amber-400 hover:underline">Lost in the Middle: How Language Models
                                        Use Long Contexts (Liu et al., 2023)</a></span>
                            </div>

                            <div
                                class="flex items-start gap-4 p-4 bg-emerald-500/5 border border-emerald-500/20 rounded-xl">
                                <i class="fas fa-arrow-trend-up text-emerald-500 mt-1"></i>
                                <div>
                                    <strong class="text-emerald-400 block mb-1">The Gain</strong>
                                    <p class="text-sm">Maintains strict context precision and saves thousands of tokens
                                        worth of API cost. The agent fetches the data only exactly when it is ready to
                                        reason about it.</p>
                                </div>
                            </div>
                        </div>
                    </section>

                    <!-- Phase 3 -->
                    <section class="mb-16 pb-16 border-b border-white/5">
                        <div class="flex items-center gap-4 mb-6">
                            <div
                                class="w-12 h-12 rounded-full bg-orange-500/10 flex items-center justify-center text-orange-500 text-xl">
                                <i class="fas fa-route"></i></div>
                            <h3 class="text-2xl font-bold text-white">03 Meta-Routing & Skill Loading</h3>
                        </div>

                        <div class="space-y-6 text-zinc-300 leading-relaxed">
                            <div>
                                <h4 class="text-white font-bold mb-2">Context & Motivation</h4>
                                <p>Loading every possible instruction, prompt constraint, and tool JSON schema (web
                                    search, codebase reading, calendar modification, PDF generation) into the system
                                    prompt for every request makes the LLM sluggish, confused, and prone to hallucinate
                                    parameter usage due to schema soup.</p>
                            </div>

                            <div>
                                <h4 class="text-white font-bold mb-2">Algorithm & Execution</h4>
                                <p>Cowork uses <strong>Progressive Disclosure</strong>. We send a microscopic system
                                    prompt and ask a fast, temperature <code>0.0</code> classifier (the Router) to
                                    categorize the user intent. Based on the categorization, only the explicit
                                    capabilities (e.g. tools, system persona, and step-by-step guidance rules) mapping
                                    to that intent are injected into the context.</p>
                            </div>

                            <div class="bg-zinc-900 border border-white/5 p-4 rounded-xl font-mono text-sm">
                                <span class="text-zinc-500">// Example Intent: "Create a slide deck about my
                                    notes"</span><br>
                                <span class="text-zinc-400">Router classification: <code>DOCUMENT_TOOLS</code>,
                                    <code>WORKSPACE_TOOLS</code></span><br>
                                <span class="text-orange-500">Injects: pptx generation schema, file reading
                                    schema.</span><br>
                                <span class="text-zinc-500">// (Leaves out web search, github, and calendar
                                    tools)</span>
                            </div>

                            <div
                                class="flex items-start gap-4 p-4 bg-emerald-500/5 border border-emerald-500/20 rounded-xl">
                                <i class="fas fa-arrow-trend-up text-emerald-500 mt-1"></i>
                                <div>
                                    <strong class="text-emerald-400 block mb-1">The Gain</strong>
                                    <p class="text-sm">Massively reduces LLM latency and cost by stripping unused
                                        schema. Focused schema prevents the LLM from trying to use a web-scrape tool
                                        when it just needs to modify a local file.</p>
                                </div>
                            </div>
                        </div>
                    </section>

                    <!-- Phase 4 -->
                    <section class="mb-16 pb-16 border-b border-white/5">
                        <div class="flex items-center gap-4 mb-6">
                            <div
                                class="w-12 h-12 rounded-full bg-rose-500/10 flex items-center justify-center text-rose-500 text-xl">
                                <i class="fas fa-map"></i></div>
                            <h3 class="text-2xl font-bold text-white">04 Planning</h3>
                        </div>

                        <div class="space-y-6 text-zinc-300 leading-relaxed">
                            <div>
                                <h4 class="text-white font-bold mb-2">Context & Motivation</h4>
                                <p>When given a complex task (e.g., "Refactor this entire API mapping"), agents that
                                    jump straight into execution often hit dead ends, forget the original goal halfway
                                    through, or get stuck looping on microscopic edge cases because they never mapped
                                    the broader terrain.</p>
                            </div>

                            <div>
                                <h4 class="text-white font-bold mb-2">Algorithm & Execution</h4>
                                <p>Before action begins, the system invokes planning. The agent generates a structured
                                    breakdown of the steps necessary to complete the task. This step roadmap is saved
                                    statically to a <code>task_goal</code> tracker inside the session's workspace. As
                                    the agent acts in Phase 5, this static plan anchors its reasoning.</p>
                            </div>

                            <div class="bg-zinc-900 border border-white/5 p-4 rounded-xl font-mono text-sm">
                                <span class="text-zinc-500">// Example File: workspace/task_goal.txt</span><br>
                                <span class="text-zinc-400">[ ] Step 1: Read existing API mapping.</span><br>
                                <span class="text-zinc-400">[ ] Step 2: Extract list of deprecated endpoints.</span><br>
                                <span class="text-zinc-400">[ ] Step 3: Rewrite routing file.</span>
                            </div>

                            <div class="flex items-center gap-2 text-sm text-zinc-400 border-l-2 border-rose-500 pl-4">
                                <i class="fas fa-book-open"></i>
                                <span>Reference: <a href="https://arxiv.org/abs/2303.11366" target="_blank"
                                        class="text-rose-400 hover:underline">Reflexion: Language Agents with Verbal
                                        Reinforcement Learning (Shinn et al., 2023)</a> — Applying self-reflection
                                    through planning.</span>
                            </div>

                            <div
                                class="flex items-start gap-4 p-4 bg-emerald-500/5 border border-emerald-500/20 rounded-xl">
                                <i class="fas fa-arrow-trend-up text-emerald-500 mt-1"></i>
                                <div>
                                    <strong class="text-emerald-400 block mb-1">The Gain</strong>
                                    <p class="text-sm">Forces "System-2" slow-thinking before acting. If an agent's
                                        memory window is compressed later, the static plan serves as an indestructible
                                        anchor to remind it what it was doing.</p>
                                </div>
                            </div>
                        </div>
                    </section>

                    <!-- Phase 5 -->
                    <section class="mb-16 pb-16 border-b border-white/5">
                        <div class="flex items-center gap-4 mb-6">
                            <div
                                class="w-12 h-12 rounded-full bg-violet-500/10 flex items-center justify-center text-violet-500 text-xl">
                                <i class="fas fa-rotate"></i></div>
                            <h3 class="text-2xl font-bold text-white">05 Execution (REACT Loop)</h3>
                        </div>

                        <div class="space-y-6 text-zinc-300 leading-relaxed">
                            <div>
                                <h4 class="text-white font-bold mb-2">Context & Motivation</h4>
                                <p>Generative models predict the next token, which makes them inherently poor at
                                    long-term, dynamic agency unless properly constrained. Open-ended "think-and-act"
                                    loops frequently fall into infinite error loops (e.g. running bad code, getting an
                                    error, predicting the same bad code again forever).</p>
                            </div>

                            <div>
                                <h4 class="text-white font-bold mb-2">Algorithm & Execution</h4>
                                <p>The reasoning phase utilizes a bounded REACT (Reason + Act) loop. The agent reasons
                                    about its status, calls a tool in parallel, and observes the real-world output.
                                    Crucially, the loop has a hard limit (<code>max_steps = 15</code>). If the loop hits
                                    step 15, execution is forcefully halted. The agent is required to make a final
                                    <em>Tool-Free</em> assessment call dictating returning partial progress, ensuring
                                    graceful failure instead of an infinite crash.</p>
                            </div>

                            <div
                                class="flex items-center gap-2 text-sm text-zinc-400 border-l-2 border-violet-500 pl-4">
                                <i class="fas fa-book-open"></i>
                                <span>Reference: <a href="https://arxiv.org/abs/2210.03629" target="_blank"
                                        class="text-violet-400 hover:underline">ReAct: Synergizing Reasoning and Acting
                                        in Language Models (Yao et al., 2022)</a></span>
                            </div>

                            <div
                                class="flex items-start gap-4 p-4 bg-emerald-500/5 border border-emerald-500/20 rounded-xl">
                                <i class="fas fa-arrow-trend-up text-emerald-500 mt-1"></i>
                                <div>
                                    <strong class="text-emerald-400 block mb-1">The Gain</strong>
                                    <p class="text-sm">Guarantees termination. Zero infinite loops. The user never has
                                        an agent process hang indefinitely in the background destroying API credits.</p>
                                </div>
                            </div>
                        </div>
                    </section>

                    <!-- Phase 6 -->
                    <section class="mb-16 pb-16 border-b border-white/5">
                        <div class="flex items-center gap-4 mb-6">
                            <div
                                class="w-12 h-12 rounded-full bg-sky-500/10 flex items-center justify-center text-sky-500 text-xl">
                                <i class="fas fa-compress-alt"></i></div>
                            <h3 class="text-2xl font-bold text-white">06 Context Compression</h3>
                        </div>

                        <div class="space-y-6 text-zinc-300 leading-relaxed">
                            <div>
                                <h4 class="text-white font-bold mb-2">Context & Motivation</h4>
                                <p>Conversations with autonomous agents accumulate massive context histories due to tool
                                    observation dumps (API responses, file contents). Pushing an ever-growing array of
                                    past messages to an LLM degrades recall performance and multiplies token cost
                                    exponentially.</p>
                            </div>

                            <div>
                                <h4 class="text-white font-bold mb-2">Algorithm & Execution</h4>
                                <p>We dynamically track the rolling token count of the conversation array. If it
                                    breaches <code>context_limit_tokens</code> (e.g. 6000), Phase 6 triggers. The system
                                    slices off the oldest half of the messages. A small, fast LLM pass performs a
                                    map-reduce summarization on these messages. The raw messages are deleted, and the
                                    dense summary is injected at the top of the array.</p>
                            </div>

                            <div
                                class="flex items-start gap-4 p-4 bg-emerald-500/5 border border-emerald-500/20 rounded-xl">
                                <i class="fas fa-arrow-trend-up text-emerald-500 mt-1"></i>
                                <div>
                                    <strong class="text-emerald-400 block mb-1">The Gain</strong>
                                    <p class="text-sm">Supports theoretically infinite session lengths. You can
                                        pair-program with Cowork for 6 hours straight without encountering
                                        context-window maximums or exorbitant message-history costs.</p>
                                </div>
                            </div>
                        </div>
                    </section>

                    <!-- Phase 7 -->
                    <section class="mb-16 pb-16">
                        <div class="flex items-center gap-4 mb-6">
                            <div
                                class="w-12 h-12 rounded-full bg-emerald-500/10 flex items-center justify-center text-emerald-500 text-xl">
                                <i class="fas fa-brain"></i></div>
                            <h3 class="text-2xl font-bold text-white">07 Memoria Ingestion (Long-Term Memory)</h3>
                        </div>

                        <div class="space-y-6 text-zinc-300 leading-relaxed">
                            <div>
                                <h4 class="text-white font-bold mb-2">Context & Motivation</h4>
                                <p>Traditional conversational agents have terminal amnesia. The moment you clear the
                                    context or start a new session, you have to re-explain who you are, what the project
                                    is, and what your preferences are (e.g., "always write code in TypeScript").</p>
                            </div>

                            <div>
                                <h4 class="text-white font-bold mb-2">Algorithm & Execution</h4>
                                <p>Memoria transforms transient facts into durable data. After an execution loop
                                    concludes, a background worker parses the successful interactions. It extracts
                                    semantic <code>(subject, predicate, object)</code> data structures. These triplets
                                    are stored in a local JSON Knowledge Graph. They are given an Exponential Weighted
                                    Average (EWA) time scale, meaning facts discussed often gain "gravity," while old,
                                    unused facts rapidly decay towards a deletion threshold.</p>
                            </div>

                            <div class="bg-zinc-900 border border-white/5 p-4 rounded-xl font-mono text-sm">
                                <span class="text-zinc-500">// Example Extraction:</span><br>
                                <span class="text-zinc-400">Subject: "User Project"</span><br>
                                <span class="text-zinc-400">Predicate: "uses Framework"</span><br>
                                <span class="text-emerald-400">Object: "TailwindCSS v3.4"</span><br>
                                <span class="text-zinc-500">// Inected automatically in every future session when CSS is
                                    mentioned.</span>
                            </div>

                            <div
                                class="flex items-center gap-2 text-sm text-zinc-400 border-l-2 border-emerald-500 pl-4">
                                <i class="fas fa-book-open"></i>
                                <span>Reference: <a href="https://arxiv.org/abs/2304.03442" target="_blank"
                                        class="text-emerald-400 hover:underline">Generative Agents: Interactive
                                        Simulacra of Human Behavior (Park et al., 2023)</a> — Applying observation
                                    reflection and memory streams.</span>
                            </div>

                            <div
                                class="flex items-start gap-4 p-4 bg-emerald-500/5 border border-emerald-500/20 rounded-xl">
                                <i class="fas fa-arrow-trend-up text-emerald-500 mt-1"></i>
                                <div>
                                    <strong class="text-emerald-400 block mb-1">The Gain</strong>
                                    <p class="text-sm">Creates an emergent, highly personalized AI coworker. The agent
                                        learns your project structure across weeks and months, completely bypassing the
                                        need for complex external Vector Databases like Pinecone.</p>
                                </div>
                            </div>
                        </div>
                    </section>

                    <h2 class="text-3xl font-bold text-white mb-6">Execution Tracing & Auditability</h2>
                    <p class="text-zinc-300 leading-relaxed mb-6">
                        One major problem with autonomous agents is the "black box" syndrome. You ask for a task, it
                        spins, and outputs code. If it fails, you don't know why.
                    </p>
                    <p class="text-zinc-300 leading-relaxed mb-12">
                        Because Makix forces state-machine boundaries via the 7 phases, every transition is logged into
                        a durable JSONL trace file (accessible via <code>cowork trace</code>). Every tool call, prompt
                        generation, error catch, and token usage integer is mapped. This provides <strong>100%
                            Traceability</strong> for mission-critical enterprise workflows.
                    </p>
                </div>
            </div>
        </main>

        <!-- Right Panel (ToC) -->
        <aside class="hidden xl:block w-72 h-screen sticky top-0 border-l border-white/5 py-24 px-8 overflow-y-auto">
            <h5 class="mb-4 text-[10px] font-bold tracking-[0.2em] text-zinc-500 uppercase">On this page</h5>
            <nav id="toc" class="space-y-3 text-sm">
                <!-- Generated by docs.js -->
            </nav>
        </aside>
    </div>

    <script type="module" src="/src/docs.js"></script>

    <script type="module" src="/src/search.js"></script>
</body>

</html>